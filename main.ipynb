{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Colab has been used to train the model below is the training code for coalb* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.20\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/Swimming_pool/data.yaml epochs=100 imgsz=800 plots=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Inference code (download the trained model and load it for running on vedio and images. )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"besty.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = \"New folder\\\\train\\images\\Screenshot-2024-11-21-122109_png.rf.5a8aefcb5f9933d57c36c2149bc7d3cf.jpg\"  \n",
    "image = cv2.imread(input_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x800 2 emptys, 1 occupied, 495.2ms\n",
      "Speed: 10.2ms preprocess, 495.2ms inference, 1.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(image,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_labels = [\"Empty\", \"Occupied\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For running on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x800 2 emptys, 1 occupied, 553.4ms\n",
      "Speed: 8.2ms preprocess, 553.4ms inference, 1.1ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(input_image_path)\n",
    "result=model.predict(image)\n",
    "empty = 0\n",
    "occupied=0\n",
    "for box in result[0].boxes:\n",
    "    x1, y1, x2, y2 = map(int, box.xyxy[0])  \n",
    "    conf = box.conf[0].item()  \n",
    "    class_id = int(box.cls[0].item())  \n",
    "    if class_id == 0:  \n",
    "        empty+= 1\n",
    "    else :\n",
    "        occupied+= 1\n",
    "        \n",
    "    label = f\"{class_labels[class_id]}: {conf:.2f}\"\n",
    "    color = (255,0, 0) if class_id == 0 else (0, 0, 255)  \n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "\n",
    "\n",
    "text1 = f\"Empty Chairs: {empty}\"\n",
    "text2 = f\"Occupied Chairs: {occupied}\"\n",
    "\n",
    "\n",
    "cv2.putText(image, text1, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2) \n",
    "cv2.putText(image, text2, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0,255), 2)  \n",
    "\n",
    "\n",
    "\n",
    "output_image_path = \"output_image6.jpg\"  # Path to save the result\n",
    "cv2.imwrite(output_image_path, image)\n",
    "cv2.imshow(\"Chair Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For running on saved vedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x800 4 emptys, 1 occupied, 387.4ms\n",
      "Speed: 6.5ms preprocess, 387.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 324.4ms\n",
      "Speed: 6.0ms preprocess, 324.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 407.2ms\n",
      "Speed: 4.5ms preprocess, 407.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 345.5ms\n",
      "Speed: 6.4ms preprocess, 345.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 303.1ms\n",
      "Speed: 4.5ms preprocess, 303.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 310.5ms\n",
      "Speed: 5.8ms preprocess, 310.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 324.1ms\n",
      "Speed: 4.8ms preprocess, 324.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 324.9ms\n",
      "Speed: 4.7ms preprocess, 324.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 323.4ms\n",
      "Speed: 5.4ms preprocess, 323.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 326.5ms\n",
      "Speed: 3.7ms preprocess, 326.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 326.8ms\n",
      "Speed: 5.9ms preprocess, 326.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 379.8ms\n",
      "Speed: 3.5ms preprocess, 379.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 417.2ms\n",
      "Speed: 8.0ms preprocess, 417.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open video source\n",
    "video_capture = cv2.VideoCapture(\"BearWakes .mp4\")  # Replace with your video path\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define display dimensions\n",
    "display_width = 800\n",
    "display_height = 600\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "output_path = \"output_video.mp4\"  # Path to save the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec for .mp4 format\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break  # Exit if the video ends or frame cannot be read\n",
    "\n",
    "    empty = 0\n",
    "    occupied = 0\n",
    "\n",
    "    # Run detection on the frame\n",
    "    result = model.predict(frame)\n",
    "    for box in result[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "        conf = box.conf[0].item()  # Confidence score\n",
    "        class_id = int(box.cls[0].item())  # Class ID\n",
    "\n",
    "        # Update counts\n",
    "        if class_id == 0:\n",
    "            empty += 1\n",
    "        else:\n",
    "            occupied += 1\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        label = f\"{class_labels[class_id]}: {conf:.2f}\"\n",
    "        color = (255, 0, 0) if class_id == 0 else (0, 0, 255)  # Color for empty/occupied\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Add total counts to the frame\n",
    "    text1 = f\"Empty Chairs: {empty}\"\n",
    "    text2 = f\"Occupied Chairs: {occupied}\"\n",
    "    cv2.putText(frame, text1, (20, 30), cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 0, 0), 2)  # Blue for empty\n",
    "    cv2.putText(frame, text2, (20, 70), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 0, 255), 2)  # Red for occupied\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    video_writer.write(frame)\n",
    "\n",
    "    # Resize frame for display\n",
    "    display_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    cv2.imshow(\"Chair Detection\", display_frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video_capture.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For live camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 1 occupied, 370.1ms\n",
      "Speed: 4.8ms preprocess, 370.1ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 occupied, 358.0ms\n",
      "Speed: 7.0ms preprocess, 358.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 occupied, 350.6ms\n",
      "Speed: 5.5ms preprocess, 350.6ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 occupied, 375.6ms\n",
      "Speed: 6.0ms preprocess, 375.6ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 occupied, 361.5ms\n",
      "Speed: 4.6ms preprocess, 361.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 occupied, 400.3ms\n",
      "Speed: 6.5ms preprocess, 400.3ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 occupied, 374.5ms\n",
      "Speed: 6.0ms preprocess, 374.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 2 occupieds, 362.6ms\n",
      "Speed: 5.0ms preprocess, 362.6ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open video source\n",
    "video_capture = cv2.VideoCapture(0)  # Replace with your video path\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define display dimensions\n",
    "display_width = 800\n",
    "display_height = 600\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "output_path = \"output_video.mp4\"  # Path to save the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec for .mp4 format\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break  # Exit if the video ends or frame cannot be read\n",
    "\n",
    "    empty = 0\n",
    "    occupied = 0\n",
    "\n",
    "    # Run detection on the frame\n",
    "    result = model.predict(frame)\n",
    "    for box in result[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "        conf = box.conf[0].item()  # Confidence score\n",
    "        class_id = int(box.cls[0].item())  # Class ID\n",
    "\n",
    "        # Update counts\n",
    "        if class_id == 0:\n",
    "            empty += 1\n",
    "        else:\n",
    "            occupied += 1\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        label = f\"{class_labels[class_id]}: {conf:.2f}\"\n",
    "        color = (255, 0, 0) if class_id == 0 else (0, 0, 255)  # Color for empty/occupied\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Add total counts to the frame\n",
    "    text1 = f\"Empty Chairs: {empty}\"\n",
    "    text2 = f\"Occupied Chairs: {occupied}\"\n",
    "    cv2.putText(frame, text1, (20, 30), cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 0, 0), 2)  # Blue for empty\n",
    "    cv2.putText(frame, text2, (20, 70), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 0, 255), 2)  # Red for occupied\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    video_writer.write(frame)\n",
    "\n",
    "    # Resize frame for display\n",
    "    display_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    cv2.imshow(\"Chair Detection\", display_frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video_capture.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
