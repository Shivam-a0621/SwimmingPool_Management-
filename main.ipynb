{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Colab has been used to train the model below is the training code for coalb* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.20\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/Swimming_pool/data.yaml epochs=100 imgsz=800 plots=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Inference code (download the trained model and load it for running on vedio code is )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhard\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"besty.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = \"swimming-pool-1796147_1280.jpg\"  \n",
    "image = cv2.imread(input_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x800 1 Occupied, 513.7ms\n",
      "Speed: 9.9ms preprocess, 513.7ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Empty', 1: 'Occupied'}\n",
      "obb: None\n",
      "orig_img: array([[[ 21,  35,  31],\n",
      "        [ 26,  40,  36],\n",
      "        [ 30,  41,  38],\n",
      "        ...,\n",
      "        [ 21,  62,  54],\n",
      "        [ 17,  60,  51],\n",
      "        [ 24,  69,  60]],\n",
      "\n",
      "       [[ 17,  31,  27],\n",
      "        [ 21,  35,  31],\n",
      "        [ 25,  36,  33],\n",
      "        ...,\n",
      "        [ 25,  66,  58],\n",
      "        [ 20,  63,  54],\n",
      "        [ 32,  77,  68]],\n",
      "\n",
      "       [[ 23,  37,  33],\n",
      "        [ 26,  40,  36],\n",
      "        [ 29,  40,  37],\n",
      "        ...,\n",
      "        [ 22,  61,  53],\n",
      "        [ 10,  51,  43],\n",
      "        [ 23,  66,  57]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 93,  96,  71],\n",
      "        [107, 110,  85],\n",
      "        [113, 115,  93],\n",
      "        ...,\n",
      "        [154, 158, 133],\n",
      "        [157, 160, 135],\n",
      "        [142, 145, 120]],\n",
      "\n",
      "       [[ 97, 100,  75],\n",
      "        [ 98, 101,  76],\n",
      "        [101, 103,  81],\n",
      "        ...,\n",
      "        [153, 156, 134],\n",
      "        [180, 183, 161],\n",
      "        [136, 138, 116]],\n",
      "\n",
      "       [[ 93,  96,  71],\n",
      "        [ 92,  95,  70],\n",
      "        [102, 105,  80],\n",
      "        ...,\n",
      "        [116, 121, 100],\n",
      "        [150, 152, 132],\n",
      "        [134, 135, 115]]], dtype=uint8)\n",
      "orig_shape: (768, 768)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict2'\n",
      "speed: {'preprocess': 9.851932525634766, 'inference': 513.7279033660889, 'postprocess': 1.4197826385498047}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_labels = [\"Empty\", \"Occupied\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x800 3 Emptys, 337.5ms\n",
      "Speed: 6.0ms preprocess, 337.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 800)\n"
     ]
    }
   ],
   "source": [
    "# input_image_path = \"images.jpg\"  \n",
    "# image = cv2.imread(input_image_path)\n",
    "# result=model.predict(image)\n",
    "# empty = 0\n",
    "# occupied=0\n",
    "# for box in result[0].boxes:\n",
    "#     x1, y1, x2, y2 = map(int, box.xyxy[0])  \n",
    "#     conf = box.conf[0].item()  \n",
    "#     class_id = int(box.cls[0].item())  \n",
    "#     if class_id == 0:  \n",
    "#         empty+= 1\n",
    "#     else :\n",
    "#         occupied+= 1\n",
    "        \n",
    "#     label = f\"{class_labels[class_id]}: {conf:.2f}\"\n",
    "#     color = (255,0, 0) if class_id == 0 else (0, 0, 255)  \n",
    "#     cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "#     cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "\n",
    "\n",
    "# text1 = f\"Empty Chairs: {empty}\"\n",
    "# text2 = f\"Occupied Chairs: {occupied}\"\n",
    "\n",
    "\n",
    "# cv2.putText(image, text1, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2) \n",
    "# cv2.putText(image, text2, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0,255), 2)  \n",
    "\n",
    "\n",
    "\n",
    "# output_image_path = \"output_image6.jpg\"  # Path to save the result\n",
    "# cv2.imwrite(output_image_path, image)\n",
    "# cv2.imshow(\"Chair Detection\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x800 4 emptys, 1 occupied, 387.4ms\n",
      "Speed: 6.5ms preprocess, 387.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 324.4ms\n",
      "Speed: 6.0ms preprocess, 324.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 407.2ms\n",
      "Speed: 4.5ms preprocess, 407.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 345.5ms\n",
      "Speed: 6.4ms preprocess, 345.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 303.1ms\n",
      "Speed: 4.5ms preprocess, 303.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 310.5ms\n",
      "Speed: 5.8ms preprocess, 310.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 324.1ms\n",
      "Speed: 4.8ms preprocess, 324.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 324.9ms\n",
      "Speed: 4.7ms preprocess, 324.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 323.4ms\n",
      "Speed: 5.4ms preprocess, 323.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 326.5ms\n",
      "Speed: 3.7ms preprocess, 326.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 326.8ms\n",
      "Speed: 5.9ms preprocess, 326.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 379.8ms\n",
      "Speed: 3.5ms preprocess, 379.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 4 emptys, 1 occupied, 417.2ms\n",
      "Speed: 8.0ms preprocess, 417.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open video source\n",
    "video_capture = cv2.VideoCapture(\"BearWakes .mp4\")  # Replace with your video path\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define display dimensions\n",
    "display_width = 800\n",
    "display_height = 600\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "output_path = \"output_video.mp4\"  # Path to save the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec for .mp4 format\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break  # Exit if the video ends or frame cannot be read\n",
    "\n",
    "    empty = 0\n",
    "    occupied = 0\n",
    "\n",
    "    # Run detection on the frame\n",
    "    result = model.predict(frame)\n",
    "    for box in result[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "        conf = box.conf[0].item()  # Confidence score\n",
    "        class_id = int(box.cls[0].item())  # Class ID\n",
    "\n",
    "        # Update counts\n",
    "        if class_id == 0:\n",
    "            empty += 1\n",
    "        else:\n",
    "            occupied += 1\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        label = f\"{class_labels[class_id]}: {conf:.2f}\"\n",
    "        color = (255, 0, 0) if class_id == 0 else (0, 0, 255)  # Color for empty/occupied\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Add total counts to the frame\n",
    "    text1 = f\"Empty Chairs: {empty}\"\n",
    "    text2 = f\"Occupied Chairs: {occupied}\"\n",
    "    cv2.putText(frame, text1, (20, 30), cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 0, 0), 2)  # Blue for empty\n",
    "    cv2.putText(frame, text2, (20, 70), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 0, 255), 2)  # Red for occupied\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    video_writer.write(frame)\n",
    "\n",
    "    # Resize frame for display\n",
    "    display_frame = cv2.resize(frame, (display_width, display_height))\n",
    "    cv2.imshow(\"Chair Detection\", display_frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video_capture.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
